#to run on tex using hive tables
pig -x tez -useHCatalog PIGPROGRAM.pig

#From HDFS, file/files in folder with no structure
grunt> a1 = load 'flightdelay' using PigStorage(',');

#From HDFS, file/files in folder with structure
grunt> A1 = load 'flightdelays' using PigStorage() AS (year:int,month:int,dayofmonth:int,ArrDely:int,Dest:chararray); -- with structure

#see the structure
grunt> describe A1;

#From HIVE: 
grunt> a1 = load 'student' using org.apache.hive.hcatalog.pig.HCatLoader();

#To HIVE: 
grunt> store a2 into 'college' using org.apache.hive.hcatalog.pig.HCatStorer();

#To HDFS: 
grunt> store a2 into '/user/horton/college' using PigStorage(',');

#if metadata.dat is where the structure is stored; below can be used to check underlying MR code
grunt> bash –x pig –f script.pig –param md=$(cat metadata.dat)

#Pig supports dryrun 
If -debug option is specified to pig, it will produce fully substituted pig script in the current working directory named 
<original name>.substituted
A -dryrun option will be added to pig in which case no execution is performed and substituted script is produced. 
We can also use the same option to produce just the execution plan.

#In case we want to load a custom schema; its a pain to deal with Pig APIs though
LOAD ‘<path>’ USING com.example.CustomLoader(‘schema.xml’)

